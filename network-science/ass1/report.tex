\documentclass[10pt]{article}

\begin{document}
\title{COMP 767 - Assignment 1}
\author{Yi Tian Xu}
\date{September 15, 2016}
\maketitle

\section{Vintage Luxury Trends}

One dataset that can interesting and challenging to look at comes from the company that I worked with in the past year. The company, LXR{\&}CO, sells vintage luxury items such as designer handbags. Currently, they have over 20 retail stores around the world and an e-commercial website open for North America customers. As the company plans to expand, a natural question  that can arise is on the sale trend of their products at different regions in the world. A analysis on this issue can potentially help them to understand the behaviour of buyers, the performance of their stores, and the efficiency of their products disctribution at different location and accross time. 

\subsection{Data Source and Network Construction}

The data gathered is a partial set from the company's database, containing all the sold and return items since the beginning of the year 2016, totalling to more than 48,000 entries. Each item has an associated store name or shipping address down to the city level, a price and discount values in a particular currency, the brand and the category name. If the item is associated with a physical store, information about whether this store's item can be accessible on the e-commerce website is also retrieved. The list of items is queried using MySQL and exported as a CSV file. 

There can be various network that we can construct with the data depending on the exact problem that we want to study. For example, we can construct bipartite graphs, linking available items to corresponding locations by edges. We can define the weight of an item vertex to be a combination of the item's attributes (price, discount, brand, category, refunded or sold, etc.). Thus the CSV file containing the list of items and their location can be considered as an edge list. 

\section{Phylogenetic Tree}

Motived by my interest in evolution theory, I choose the phylogenetic tree for my second network. Defining species as vertices and evolutionary relationships as edges, we can obtain a DAG. We can call a species $u$ a child of species $v$ if species $u$ is evolved from species $v$ and no other species is in any path from $u$ to $v$. This relationship can be marked by a directed edge from child to parent. If there are at least two vertices in a path from $u$ to $v$, we call $v$ an ancestor of $u$. We also call a path from a vertices $u$ to a root a evolutionary path of species $u$. Some potentially interesting exercises that can be done with this network are visualization and clustering (e.g.: classifying species into families). 

\subsection{Data Source and Gathering Method}

The data I gathered is from the Ensembl Rest API (https://rest.ensembl.org). Their taxonomic classification endpoint returns a list of species in the evolutionary path of the queried species. Each returned species contains the parent and a list of children.

The method that I used is a Python script that recursively queries for the children and parent until all the species are collected. The scripts saves a list of edges in a CSV file. As each species in Ensembl Rest API has one parent, the number of vertices should be equal to the number of edges. 

I ran the script starting with species \emph{Eukaryota} and stopped after gathering 5508 vertices and edges, giving me a partial set of all Ensembl's species. 

\subsection{Encountered Issues}

There are various inconsistency in Ensembl returned response. For example, when \emph{Homo Sapien} is queried, one of the ancestors \emph{Eukaryota} has only one child, while when \emph{Eukaryota} is queried, this species has 22 children. This response format may have been a design that was chosen for the API's benefit. To avoid missing data, I designed the script to query all encountered species at least once, making the script significantly long to run. Had Ensembl return the complete children list for each returned species, the script would only need to iterate through the children, which could have save much request call time. 

Another minor issue encountered was the unstable internet connection while running the script. I solve this problem by the dumping current state of the script into a file after detecting connection error and load the previous state on restart. Likewise, I can resume where the script stopped everytime a connection failure happens. 

\end{document}
